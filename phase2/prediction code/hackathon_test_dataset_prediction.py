# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AkYsMWXt_6TNEyHN6oqkXrCqaBKejvoI
"""

!pip install onnxruntime

import os
import sys
import logging
import time
import json
import numpy as np
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import onnxruntime as ort
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score
from google.colab import files

log_filename = "prediction_run.log"
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler(log_filename, mode="w"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)
logger.info("Hackathon Phase 2 Inference Started")

print("Please upload your hackathon_test_dataset zip file")
uploaded = files.upload()
zip_name = list(uploaded.keys())[0]
print("Unzipping...")
os.system(f"unzip -q '{zip_name}'")
print("✅ Done! Test dataset is ready!")

TRAINING_CLASS_NAMES = [
    "Bridge",
    "Clean",
    "CMP_scratch",
    "Cracks",
    "LER",
    "Malformed_Via",
    "Opens",
    "Others"
]

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
MODEL_PATH = "wafer_defect_model.onnx"
TEST_DATASET_DIR = "hackathon_test_dataset"

print("✅ Configuration set!")
print("Classes:", TRAINING_CLASS_NAMES)

TRAINING_CLASS_NAMES = [
    "Bridge",
    "Clean",
    "CMP_scratch",
    "Cracks",
    "LER",
    "Malformed_Via",
    "Opens",
    "Others"
]

CLASS_NAME_MAP = {
    "CMP"      : "CMP_scratch",
    "Crack"    : "Cracks",
    "Open"     : "Opens",
    "Other"    : "Others",
    "Particle"  : "Others",
    "VIA"      : "Malformed_Via",
}

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
MODEL_PATH = "wafer_defect_model.onnx"
TEST_DATASET_DIR = "hackathon_test_dataset"

print("✅ Configuration set!")
print("Classes:", TRAINING_CLASS_NAMES)
print("Mapping:", CLASS_NAME_MAP)

print("Please upload your wafer_defect_model.onnx file")
files.upload()

session = ort.InferenceSession(MODEL_PATH, providers=["CPUExecutionProvider"])

input_name  = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name

print("✅ Model loaded successfully!")
print("Input name :", input_name)
print("Output name:", output_name)

folders = os.listdir(TEST_DATASET_DIR)
print("✅ Test dataset folders found:")
for f in folders:
    print(" -", f)

def preprocess_image(image_path):
    img = cv2.imread(image_path)
    if img is None:
        return None
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (224, 224))
    img = img.astype(np.float32)  # NO /255 this time
    return img

print("✅ Preprocessing fixed!")

y_true_names    = []
y_pred_names    = []
image_paths_log = []
confidence_list = []
skipped = 0
total   = 0
start_time = time.time()

raw_test_classes = folders

def run_batch(batch_imgs):
    inputs = np.array(batch_imgs, dtype=np.float32)
    ort_inputs = {input_name: inputs}
    ort_outs = session.run([output_name], ort_inputs)
    return ort_outs[0]

for raw_class in raw_test_classes:
    train_class = CLASS_NAME_MAP.get(raw_class, raw_class)
    class_dir   = os.path.join(TEST_DATASET_DIR, raw_class)
    image_files = [
        f for f in os.listdir(class_dir)
        if f.lower().endswith((".png", ".jpg", ".jpeg", ".bmp", ".tiff"))
    ]
    print(f"Processing '{raw_class}' → '{train_class}' | {len(image_files)} images")

    batch_imgs  = []
    batch_paths = []

    for img_file in image_files:
        img_path = os.path.join(class_dir, img_file)
        img = preprocess_image(img_path)
        if img is None:
            skipped += 1
            continue
        batch_imgs.append(img)
        batch_paths.append(img_path)
        total += 1

        if len(batch_imgs) == BATCH_SIZE:
            preds = run_batch(batch_imgs)
            for i, pred in enumerate(preds):
                pred_idx  = int(np.argmax(pred))
                y_true_names.append(train_class)
                y_pred_names.append(TRAINING_CLASS_NAMES[pred_idx])
                image_paths_log.append(batch_paths[i])
                confidence_list.append(float(pred[pred_idx]))
            batch_imgs  = []
            batch_paths = []

    if batch_imgs:
        preds = run_batch(batch_imgs)
        for i, pred in enumerate(preds):
            pred_idx  = int(np.argmax(pred))
            y_true_names.append(train_class)
            y_pred_names.append(TRAINING_CLASS_NAMES[pred_idx])
            image_paths_log.append(batch_paths[i])
            confidence_list.append(float(pred[pred_idx]))

elapsed = time.time() - start_time
print(f"\n✅ Done! {total} images processed in {elapsed:.2f} seconds")

all_labels = sorted(set(y_true_names) | set(y_pred_names))

accuracy  = accuracy_score(y_true_names, y_pred_names)
precision = precision_score(y_true_names, y_pred_names, labels=all_labels, average="weighted", zero_division=0)
recall    = recall_score(y_true_names, y_pred_names, labels=all_labels, average="weighted", zero_division=0)

print("=" * 45)
print("RESULTS")
print("=" * 45)
print(f"Accuracy  : {accuracy  * 100:.2f}%")
print(f"Precision : {precision * 100:.2f}%")
print(f"Recall    : {recall    * 100:.2f}%")
print("=" * 45)
print(classification_report(y_true_names, y_pred_names, labels=all_labels, zero_division=0))

cm = confusion_matrix(y_true_names, y_pred_names, labels=all_labels)

plt.figure(figsize=(12, 10))
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=all_labels,
    yticklabels=all_labels,
)
plt.title(f"Wafer Defect Detection — Confusion Matrix\nAccuracy: {accuracy*100:.2f}%", fontsize=14)
plt.ylabel("Actual Class", fontsize=12)
plt.xlabel("Predicted Class", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig("confusion_matrix.png", dpi=150)
plt.show()
print("✅ Confusion matrix saved!")

# Save log file
with open("prediction_run.log", "w") as f:
    f.write("DeepTech Hackathon Phase 2 - Prediction Log\n")
    f.write("=" * 45 + "\n")
    f.write(f"Total Images  : {total}\n")
    f.write(f"Accuracy      : {accuracy  * 100:.2f}%\n")
    f.write(f"Precision     : {precision * 100:.2f}%\n")
    f.write(f"Recall        : {recall    * 100:.2f}%\n")
    f.write("=" * 45 + "\n")
    f.write(classification_report(y_true_names, y_pred_names, labels=all_labels, zero_division=0))

print("✅ Log file saved!")

# Download all files
files.download("prediction_run.log")
files.download("confusion_matrix.png")
print("✅ Files downloaded!")